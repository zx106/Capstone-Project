{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, roc_auc_score"
      ],
      "metadata": {
        "id": "zHNjl2ObfDJ8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/drive')\n",
        "# Read the data file\n",
        "data = pd.read_csv('/drive/MyDrive/final.II.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "gk3o336gP_JT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50dae24e-4075-4374-8e3d-b07dc5ca5c53"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model without interaction for saturated model\n",
        "model_without_interaction <- glm(Last_Financing_Deal_Type ~State_incorporation+Type_entity+TRADED+five+thirteen+Num_of_name+fame_included, family = binomial(), combine)"
      ],
      "metadata": {
        "id": "rLmoiv8CTkp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the predictors you want to include in the model\n",
        "predictors = [\"State_incorporation\", \"Type_entity\", \"TRADED\", \"five\", \"thirteen\", \"Num_of_name\"]\n",
        "\n",
        "# Extract the predictors and outcome variable from the DataFrame\n",
        "X = data[predictors]\n",
        "y = data['Last_Financing_Deal_Type']\n",
        "\n",
        "# Create the logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Perform cross-validation\n",
        "scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "           'precision': make_scorer(precision_score, average='weighted'),\n",
        "           'recall': make_scorer(recall_score, average='weighted'),\n",
        "           'roc_auc': make_scorer(roc_auc_score, average='weighted')}\n",
        "\n",
        "cv_results = cross_validate(model, X, y, cv=10, scoring=scoring)\n",
        "\n",
        "# Calculate the average performance scores\n",
        "avg_scores = {}\n",
        "for metric in scoring:\n",
        "    avg_scores[metric] = cv_results[f'test_{metric}'].mean()\n",
        "\n",
        "# Calculate the specificity and misclassification rate\n",
        "specificity = 1 - avg_scores['recall']\n",
        "misclassification_rate = 1 - avg_scores['accuracy']\n",
        "\n",
        "# Create a DataFrame to store the average scores\n",
        "results = pd.DataFrame(avg_scores, index=['Average'])\n",
        "\n",
        "# Add specificity and misclassification rate to the results DataFrame\n",
        "results['Specificity'] = specificity\n",
        "results['Misclassification Rate'] = misclassification_rate\n",
        "\n",
        "# Print the results table\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to3u5MwyTg7a",
        "outputId": "53bee9f2-81f7-41d3-d56d-1f0dac3368be"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         accuracy  precision    recall   roc_auc  Specificity  \\\n",
            "Average  0.707143   0.640291  0.707143  0.692204     0.292857   \n",
            "\n",
            "         Misclassification Rate  \n",
            "Average                0.292857  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{r LRT model all}\n",
        "State_incorporation+Type_entity+TRADED+five+thirteen+Num_of_name+fame_included+five*fame_included+Num_of_name*five+Num_of_name*thirteen+five*State_incorporation+thirteen*State_incorporation"
      ],
      "metadata": {
        "id": "d8x6-JBIUbmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the predictors you want to include in the model\n",
        "X = data[[\"State_incorporation\", \"Type_entity\", \"TRADED\", \"five\", \"thirteen\", \"Num_of_name\"]]\n",
        "y = data['Last_Financing_Deal_Type']\n",
        "# Add the interaction term to the predictors\n",
        "\n",
        "X['interaction1'] = X['thirteen'] * X['State_incorporation']\n",
        "X['interaction2'] = X['Num_of_name'] * X['five']\n",
        "X['interaction3'] = X['Num_of_name'] * X['thirteen']\n",
        "X['interaction4'] = X['five'] * X['State_incorporation']\n",
        "\n",
        "\n",
        "# Create the logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Perform cross-validation\n",
        "scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "           'precision': make_scorer(precision_score, average='weighted'),\n",
        "           'recall': make_scorer(recall_score, average='weighted'),\n",
        "           'roc_auc': make_scorer(roc_auc_score, average='weighted')}\n",
        "\n",
        "cv_results = cross_validate(model, X, y, cv=10, scoring=scoring)\n",
        "\n",
        "# Calculate the average performance scores\n",
        "avg_scores = {}\n",
        "for metric in scoring:\n",
        "    avg_scores[metric] = cv_results[f'test_{metric}'].mean()\n",
        "\n",
        "# Calculate the specificity and misclassification rate\n",
        "specificity = 1 - avg_scores['recall']\n",
        "misclassification_rate = 1 - avg_scores['accuracy']\n",
        "\n",
        "# Create a DataFrame to store the average scores\n",
        "results = pd.DataFrame(avg_scores, index=['Average'])\n",
        "\n",
        "# Add specificity and misclassification rate to the results DataFrame\n",
        "results['Specificity'] = specificity\n",
        "results['Misclassification Rate'] = misclassification_rate\n",
        "\n",
        "# Print the results table\n",
        "print(results)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Hl1Gs6WUmeY",
        "outputId": "8ac0fcd7-ccc4-40c4-fdaf-18426655258e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         accuracy  precision    recall   roc_auc  Specificity  \\\n",
            "Average  0.703571   0.595874  0.703571  0.688038     0.296429   \n",
            "\n",
            "         Misclassification Rate  \n",
            "Average                0.296429  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-a5bc98459d26>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['interaction1'] = X['thirteen'] * X['State_incorporation']\n",
            "<ipython-input-4-a5bc98459d26>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['interaction2'] = X['Num_of_name'] * X['five']\n",
            "<ipython-input-4-a5bc98459d26>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['interaction3'] = X['Num_of_name'] * X['thirteen']\n",
            "<ipython-input-4-a5bc98459d26>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['interaction4'] = X['five'] * X['State_incorporation']\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{r LRT model with most important predictors and all interaction terms}\n",
        "five+thirteen+Num_of_name+fame_included+five*fame_included+Num_of_name*five+Num_of_name*thirteen"
      ],
      "metadata": {
        "id": "-DJmrE17V67h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the predictors you want to include in the model\n",
        "X = data[[\"five\", \"thirteen\", \"Num_of_name\"]]\n",
        "y = data['Last_Financing_Deal_Type']\n",
        "# Add the interaction term to the predictors\n",
        "\n",
        "\n",
        "X['interaction1'] = X['Num_of_name'] * X['five']\n",
        "X['interaction2'] = X['Num_of_name'] * X['thirteen']\n",
        "\n",
        "\n",
        "# Create the logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Perform cross-validation\n",
        "scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "           'precision': make_scorer(precision_score, average='weighted'),\n",
        "           'recall': make_scorer(recall_score, average='weighted'),\n",
        "           'roc_auc': make_scorer(roc_auc_score, average='weighted')}\n",
        "\n",
        "cv_results = cross_validate(model, X, y, cv=10, scoring=scoring)\n",
        "\n",
        "# Calculate the average performance scores\n",
        "avg_scores = {}\n",
        "for metric in scoring:\n",
        "    avg_scores[metric] = cv_results[f'test_{metric}'].mean()\n",
        "\n",
        "# Calculate the specificity and misclassification rate\n",
        "specificity = 1 - avg_scores['recall']\n",
        "misclassification_rate = 1 - avg_scores['accuracy']\n",
        "\n",
        "# Create a DataFrame to store the average scores\n",
        "results = pd.DataFrame(avg_scores, index=['Average'])\n",
        "\n",
        "# Add specificity and misclassification rate to the results DataFrame\n",
        "results['Specificity'] = specificity\n",
        "results['Misclassification Rate'] = misclassification_rate\n",
        "\n",
        "# Print the results table\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF32hevLWEz2",
        "outputId": "188240da-cfb7-44b1-b86b-0252f0c60ecc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         accuracy  precision    recall   roc_auc  Specificity  \\\n",
            "Average  0.703571   0.595874  0.703571  0.688038     0.296429   \n",
            "\n",
            "         Misclassification Rate  \n",
            "Average                0.296429  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-c5b797d3a952>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['interaction1'] = X['Num_of_name'] * X['five']\n",
            "<ipython-input-9-c5b797d3a952>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['interaction2'] = X['Num_of_name'] * X['thirteen']\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{r LRT model with most important predictors without interaction terms}\n",
        "five+thirteen+Num_of_name+fame_included"
      ],
      "metadata": {
        "id": "OwaiMu_TW1Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Specify the predictors you want to include in the model\n",
        "predictors = ['five', 'thirteen', 'Num_of_name']\n",
        "\n",
        "# Extract the predictors and outcome variable from the DataFrame\n",
        "X = data[predictors]\n",
        "y = data['Last_Financing_Deal_Type']\n",
        "\n",
        "# Create the logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Perform cross-validation\n",
        "scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "           'precision': make_scorer(precision_score, average='weighted'),\n",
        "           'recall': make_scorer(recall_score, average='weighted'),\n",
        "           'roc_auc': make_scorer(roc_auc_score, average='weighted')}\n",
        "\n",
        "cv_results = cross_validate(model, X, y, cv=10, scoring=scoring)\n",
        "\n",
        "# Calculate the average performance scores\n",
        "avg_scores = {}\n",
        "for metric in scoring:\n",
        "    avg_scores[metric] = cv_results[f'test_{metric}'].mean()\n",
        "\n",
        "# Calculate the specificity and misclassification rate\n",
        "specificity = 1 - avg_scores['recall']\n",
        "misclassification_rate = 1 - avg_scores['accuracy']\n",
        "\n",
        "# Create a DataFrame to store the average scores\n",
        "results = pd.DataFrame(avg_scores, index=['Average'])\n",
        "\n",
        "# Add specificity and misclassification rate to the results DataFrame\n",
        "results['Specificity'] = specificity\n",
        "results['Misclassification Rate'] = misclassification_rate\n",
        "\n",
        "# Print the results table\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJfJIQHdXDnz",
        "outputId": "161e02b8-3ffa-4428-ac71-aad3db825405"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         accuracy  precision    recall   roc_auc  Specificity  \\\n",
            "Average  0.714286   0.643222  0.714286  0.700538     0.285714   \n",
            "\n",
            "         Misclassification Rate  \n",
            "Average                0.285714  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AIC Optimization model: five + thirteen + fame_included"
      ],
      "metadata": {
        "id": "eD0hw-mKXe6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the predictors you want to include in the model\n",
        "predictors = ['five', 'thirteen']\n",
        "\n",
        "# Extract the predictors and outcome variable from the DataFrame\n",
        "X = data[predictors]\n",
        "y = data['Last_Financing_Deal_Type']\n",
        "\n",
        "# Create the logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Perform cross-validation\n",
        "scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "           'precision': make_scorer(precision_score, average='weighted'),\n",
        "           'recall': make_scorer(recall_score, average='weighted'),\n",
        "           'roc_auc': make_scorer(roc_auc_score, average='weighted')}\n",
        "\n",
        "cv_results = cross_validate(model, X, y, cv=10, scoring=scoring)\n",
        "\n",
        "# Calculate the average performance scores\n",
        "avg_scores = {}\n",
        "for metric in scoring:\n",
        "    avg_scores[metric] = cv_results[f'test_{metric}'].mean()\n",
        "\n",
        "# Calculate the specificity and misclassification rate\n",
        "specificity = 1 - avg_scores['recall']\n",
        "misclassification_rate = 1 - avg_scores['accuracy']\n",
        "\n",
        "# Create a DataFrame to store the average scores\n",
        "results = pd.DataFrame(avg_scores, index=['Average'])\n",
        "\n",
        "# Add specificity and misclassification rate to the results DataFrame\n",
        "results['Specificity'] = specificity\n",
        "results['Misclassification Rate'] = misclassification_rate\n",
        "\n",
        "# Print the results table\n",
        "print(results)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q76OkZ7FXeWm",
        "outputId": "f718a31b-a774-4e35-ab17-cc35995034e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         accuracy  precision    recall   roc_auc  Specificity  \\\n",
            "Average  0.701786   0.594861  0.701786  0.685954     0.298214   \n",
            "\n",
            "         Misclassification Rate  \n",
            "Average                0.298214  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{r model 5 and interaction term}\n",
        "five + thirteen + fame_included+five*fame_included"
      ],
      "metadata": {
        "id": "Nx-NYU4JXsGU"
      }
    }
  ]
}