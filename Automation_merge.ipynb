{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from google.colab import drive \n",
        "drive.mount('/drive')\n",
        "#new_datasets_sum.to_csv(\"/drive/My Drive/Colab Notebooks/ipo_exit/MA_transformed.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J9HdqRuz_o1",
        "outputId": "e25beec6-f422-4475-b180-0425f6e71d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiG0NNmvZI_j"
      },
      "outputs": [],
      "source": [
        "# import modules \n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "biotech=pd.read_csv('/drive/My Drive/Healthcare UROP/Fall 2022/Smaller Class Data/biotech.csv')\n",
        "pitchbook=pd.read_csv('/drive/My Drive/Healthcare UROP/Fall 2022/Smaller Class Data/pitchbook.csv')\n",
        "#merged_biotech=pd.read_csv('/drive/My Drive/Healthcare UROP/Fall 2022/Smaller Class Data/merged_biotech.csv')\n"
      ],
      "metadata": {
        "id": "0vNHBmZNxVzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_biotech(biotech, pitchbook):\n",
        "    match_dict={}\n",
        "    Copy_biotech=biotech.copy(deep=True)\n",
        "    Copy_pitchbook=pitchbook.copy(deep=True)\n",
        "    current=list(Copy_biotech[\"Lower_Company_name\"])\n",
        "    ipo=list(Copy_pitchbook[\"Lower_Company_Legal_Name\"])\n",
        "    for n in range(len(current)): \n",
        "      for m in range(len(ipo)): \n",
        "        if current[n]==ipo[m]: \n",
        "          match_dict[n]=m \n",
        "    return match_dict\n",
        "\n"
      ],
      "metadata": {
        "id": "4JLlG2rijTUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_now=find_biotech(biotech, pitchbook)"
      ],
      "metadata": {
        "id": "iWS7oKxQ0-Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_all(dict_now, biotech, pitchbook):   \n",
        "     \n",
        "    dict_now_key=list(dict_now.keys())\n",
        "    dict_now_value=list(dict_now.values())         \n",
        "       \n",
        "    Copy_ipo_new=pitchbook.copy(deep=True)\n",
        "    Copy_data=biotech.copy(deep=True)\n",
        "    \n",
        "    current_columns=list(Copy_data.columns)\n",
        "    ipo_columns=list(Copy_ipo_new.columns)\n",
        "    new_col=current_columns+ipo_columns\n",
        "    new_datasets_sum=pd.DataFrame(columns=new_col)\n",
        "    \n",
        "    \n",
        "    for n in range(len(dict_now_key)): \n",
        "        current_row=Copy_data.loc[dict_now_key[n]]\n",
        "        ipo_row=Copy_ipo_new.loc[dict_now_value[n]]\n",
        "        combine_row=list(pd.concat([current_row, ipo_row], axis=0, ignore_index=True))\n",
        "        new_datasets_sum.loc[n]=combine_row\n",
        "      \n",
        "    return new_datasets_sum"
      ],
      "metadata": {
        "id": "WCTLO8qJ3nmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_datasets=merge_all(dict_now, biotech, pitchbook)"
      ],
      "metadata": {
        "id": "UBqZolUg1ZRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_datasets.to_csv('/drive/My Drive/Healthcare UROP/Fall 2022/Smaller Class Data/final_biotech.csv')"
      ],
      "metadata": {
        "id": "39B467Ss4U6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "try to match words but failed"
      ],
      "metadata": {
        "id": "b4N3-NqIjUPE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMIudkaLZkab"
      },
      "outputs": [],
      "source": [
        "########################## first words ##########################\n",
        "##############################################################################\n",
        "\n",
        "def find_words(biotech, pitchbook): \n",
        "    # copy data \n",
        "    Copy_data=biotech.copy(deep=True)\n",
        "    Copy_pitch=pitchbook.copy(deep=True)\n",
        "    \n",
        "    #clean data \n",
        "    Copy_pitch['Company_Legal_Name'] = Copy_pitch['Company_Legal_Name'].apply(str)\n",
        "    Copy_pitch['Company_Legal_Name'] = Copy_pitch['Company_Legal_Name'].str.lower()\n",
        "  \n",
        "\n",
        "    Copy_data[\"Company_name\"] = Copy_data[\"Company_name\"].apply(str)\n",
        "    Copy_data[\"Company_name\"] = Copy_data[\"Company_name\"].str.lower()\n",
        "    \n",
        "    \n",
        "    current_first_word_name=[]\n",
        "    current_first_word_dict={}\n",
        "    for j in range(len(Copy_data)):\n",
        "        company=Copy_data.Company_name[j].lower()\n",
        "        if company !=\"\": \n",
        "            #1 for ipo1 \n",
        "            #first_word=company.split()[0]\n",
        "            #2 for ipo2 \n",
        "            first_word=company.split()[0:2]\n",
        "            \n",
        "            #first_word=company[0:2]\n",
        "            current_first_word_name.append(first_word)\n",
        "            current_first_word_dict[company]=j\n",
        "              \n",
        "            #if len(company.split())>=2: \n",
        "                #first_word=company.split()[0:2]\n",
        "                #current_first_word_name.append(first_word)\n",
        "                #current_first_word_dict[company]=j\n",
        "              \n",
        "            #else: \n",
        "                #current_first_word_name.append(company)\n",
        "                #current_first_word_dict[company]=j\n",
        "                \n",
        "        else: \n",
        "            current_first_word_name.append(\"\")\n",
        "            current_first_word_dict[\"\"]=j\n",
        "            \n",
        "       \n",
        "    #sdc: first word\n",
        "    ipo_first_word_name=[]\n",
        "    ipo_first_word_dict={}\n",
        "    ipo_first_company_legal=[]\n",
        "    ipo_first_company_legal_dict={}\n",
        "    ipo_first_company_also=[]\n",
        "    ipo_first_company_also_dict={}\n",
        "    ipo_first_company_former=[]\n",
        "    ipo_first_company_former_dict={}\n",
        "    \n",
        "    for k in range(len(Copy_pitch)):\n",
        "        issuer=Copy_pitch.Company_Legal_Name[k].lower()\n",
        "        if issuer !=\"\": \n",
        "            #1 for ipo1 \n",
        "            #first_word=company.split()[0]\n",
        "            #2 for ipo2 \n",
        "            if len(issuer.split())>=2: \n",
        "                first_word=issuer.split()[0:2]\n",
        "                ipo_first_word_name.append(first_word)\n",
        "                ipo_first_word_dict[issuer]=k\n",
        "                \n",
        "            if len(issuer.split())==1: \n",
        "                first_word=issuer.split()[0]\n",
        "            #first_word=issuer[0:2]\n",
        "                ipo_first_word_name.append(first_word)\n",
        "                ipo_first_word_dict[issuer]=k\n",
        "            \n",
        "            #if len(issuer.split())>=2: \n",
        "                #first_word=issuer.split()[0:2]\n",
        "                #sdc_first_word_name.append(first_word)\n",
        "                #sdc_first_word_dict[issuer]=k\n",
        "            #else: \n",
        "                #sdc_first_word_name.append(issuer)\n",
        "                #sdc_first_word_dict[issuer]=k\n",
        "        else: \n",
        "            ipo_first_word_name.append(\"\")\n",
        "            ipo_first_word_dict[\"\"]=k\n",
        "    \n",
        "    return current_first_word_name, current_first_word_dict, ipo_first_word_name, ipo_first_word_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsMRGfz3ZqWH"
      },
      "outputs": [],
      "source": [
        "current_first_word_name, current_first_word_dict, ipo_first_word_name, ipo_first_word_dict=find_words(biotech, pitchbook)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ipo_first_word_name"
      ],
      "metadata": {
        "id": "r3b_xCs033sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqXOIO1qZq_h"
      },
      "outputs": [],
      "source": [
        "list_words=[current_first_word_name, current_first_word_dict, ipo_first_word_name, ipo_first_word_dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgxTzVnkZtIO"
      },
      "outputs": [],
      "source": [
        "def match_words(list_words, biotech, pitchbook):     \n",
        "    word_dict={}\n",
        "    current_list=[]\n",
        "    ipo_list=[]\n",
        "    \n",
        "    current_first_word_name=list_words[0]\n",
        "    current_first_word_dict=list_words[1]\n",
        "    ipo_first_word_name=list_words[2]\n",
        "    ipo_first_word_dict=list_words[3]\n",
        "    \n",
        "    for n in range(len(current_first_word_name)): \n",
        "        current_word=current_first_word_name[n]\n",
        "        for m in range(len(ipo_first_word_name)): \n",
        "            ipo_word=ipo_first_word_name[m]\n",
        "            \n",
        "            \n",
        "            if len(ipo_word)==2: \n",
        "                if current_word==ipo_word: \n",
        "                    word_dict[n]=m \n",
        "                    current_list.append(current_word)\n",
        "                    ipo_list.append(ipo_word)\n",
        "            else:             \n",
        "                if current_word[0]==ipo_word: \n",
        "                    word_dict[n]=m \n",
        "                    current_list.append(current_word)\n",
        "                    ipo_list.append(ipo_word)\n",
        "        \n",
        "    return word_dict, current_list, ipo_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLR45rFDZvlB"
      },
      "outputs": [],
      "source": [
        "word_dict, current_list, ipo_list=match_words(list_words, biotech, pitchbook)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ipo_list"
      ],
      "metadata": {
        "id": "nJVra74A1Ivy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfsuI2B4Z2X4"
      },
      "outputs": [],
      "source": [
        "def justify_by_check(word_dict, biotech, pitchbook): \n",
        "  list_sum=[]\n",
        "  for key, value in word_dict.items(): \n",
        "      list_ele=[biotech.Company_name[key].lower(), pitchbook.Company_Legal_Name[value].lower()]\n",
        "      list_sum.append(list_ele)\n",
        "  return list_sum "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7Me2RevaNdW"
      },
      "outputs": [],
      "source": [
        "dict_now=word_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKUWgo4KaR2H"
      },
      "outputs": [],
      "source": [
        "##############################################################################    \n",
        "########################### Merge Datasets ############################  \n",
        "##############################################################################  \n",
        "\n",
        "def standardize_column(current, ipo, dict_now): \n",
        "    column_change_name=['Number', 'Company', 'Former name', 'Also known as', \n",
        "    'Legal name', 'Business description', \n",
        "    'Industry code', 'Financing status', 'Total raised', \n",
        "    'Year founded', 'Business status',\n",
        "    'HQ location', 'HQ post code', 'Active investors', \n",
        "    'Former investor', 'First financing date',\n",
        "    'First financing size', 'First financing deal type', 'First financing class', \n",
        "    'Last financing date', 'Last financing size', 'Last deal type', \n",
        "    'Last financing class', 'Total patents',\n",
        "    'First financing deal type 2', 'First financing deal type 3', \n",
        "    'Last financing deal type 2', 'Last financing deal type 3']\n",
        "    \n",
        "    column_key_name=['Number', 'Company', 'Former name', 'Also', 'Legal', 'Description','Code', 'Financing status', \n",
        "    'Raised', 'Year', 'Business status','Location','Post', 'Active', 'Former investors', 'First date',\n",
        "    'First size', 'first deal type', 'First class', 'Last date', \n",
        "    'Last size', 'Last type', 'Last class', 'Patent', \n",
        "    'First type 2', 'First type 3', 'Last type 2', 'Last type 3']\n",
        "    \n",
        "    \n",
        "    Copy_data=current.copy(deep=True)\n",
        "    Copy_ipo=ipo.copy(deep=True)\n",
        "    col1=list(Copy_ipo.columns)\n",
        "    column_ipo=[i.lower() for i in col1]\n",
        "  \n",
        "    \n",
        "    #nth ipo column \n",
        "    column_seperate=[]\n",
        "    for n in range(len(column_ipo)): \n",
        "        len_n=len(column_ipo[n].split())\n",
        "        seperate_n=column_ipo[n].split()[0:len_n]\n",
        "        column_seperate.append(seperate_n)\n",
        "    \n",
        "    \n",
        "    column_key_name=[i.lower() for i in column_key_name]\n",
        "    column_key_seperate=[]\n",
        "    for k in range(len(column_key_name)): \n",
        "        len_k=len(column_key_name[k].split())\n",
        "        seperate_k=column_key_name[k].split()[0:len_k]\n",
        "        column_key_seperate.append(seperate_k)\n",
        "    \n",
        "    list_real=[None]*(len(column_key_name))\n",
        "    list_to_remember=[]\n",
        "    for j in range(len(column_ipo)): \n",
        "        real=column_ipo[j]\n",
        "        if real=='company': \n",
        "            list_real[1]=col1[j]\n",
        "            list_to_remember.append(1)\n",
        "            \n",
        "        if real=='first financing deal type': \n",
        "            list_real[17]=col1[j]\n",
        "            list_to_remember.append(17)\n",
        "        \n",
        "        if real=='last financing deal type': \n",
        "            list_real[21]=col1[j]\n",
        "            list_to_remember.append(21)\n",
        "\n",
        "        \n",
        "        for k in range(len(column_key_seperate)): \n",
        "            model=column_key_seperate[k]\n",
        "            if all(word in real for word in model):\n",
        "                if k!=1: \n",
        "                  if k!=17: \n",
        "                    if k!=21: \n",
        "                      list_real[k]=col1[j]\n",
        "                      list_to_remember.append(k)\n",
        "                \n",
        "    \n",
        "    list_not_exiting={}  \n",
        "    copy_col=list_real.copy()\n",
        "    for n in range(len(column_key_name)): \n",
        "        if n not in list_to_remember: \n",
        "            list_not_exiting[n]=column_change_name[n]\n",
        "            copy_col[n]=column_change_name[n]\n",
        "              \n",
        "    return list_real, list_not_exiting, copy_col\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvRqzbAKaWCI"
      },
      "outputs": [],
      "source": [
        "list_real, list_not_exiting, copy_col=standardize_column(biotech, pitchbook, dict_now)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3O-6zbWaXkx"
      },
      "outputs": [],
      "source": [
        "def row_transform_ipo(ipo, dict_now, list_real, copy_col): \n",
        "    Copy_ipo=ipo.copy(deep=True)\n",
        "    ipo_new_datasets=pd.DataFrame(columns=copy_col)\n",
        "    \n",
        "    for k in range(len(list_real)): \n",
        "      if list_real[k] is not None: \n",
        "        ipo_new_datasets[copy_col[k]]=Copy_ipo[list_real[k]]\n",
        "    return ipo_new_datasets\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fQRjjSmab9f"
      },
      "outputs": [],
      "source": [
        "ipo_new_datasets=row_transform_ipo(pitchbook, dict_now, list_real, copy_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVWlXqJHacmW"
      },
      "outputs": [],
      "source": [
        "def merge_all(dict_now, current, ipo_new_datasets, list_real):   \n",
        "     \n",
        "    dict_now_key=list(dict_now.keys())\n",
        "    dict_now_value=list(dict_now.values())         \n",
        "       \n",
        "    Copy_ipo_new=ipo_new_datasets.copy(deep=True)\n",
        "    Copy_data=current.copy(deep=True)\n",
        "    \n",
        "    current_columns=list(Copy_data.columns)\n",
        "    ipo_columns=list(Copy_ipo_new.columns)\n",
        "    new_col=current_columns+ipo_columns\n",
        "    new_datasets_sum=pd.DataFrame(columns=new_col)\n",
        "    \n",
        "    \n",
        "    for n in range(len(dict_now_key)): \n",
        "        current_row=Copy_data.loc[dict_now_key[n]]\n",
        "        ipo_row=Copy_ipo_new.loc[dict_now_value[n]]\n",
        "        combine_row=list(pd.concat([current_row, ipo_row], axis=0, ignore_index=True))\n",
        "        new_datasets_sum.loc[n]=combine_row\n",
        "    key_dict=list(dict_now.keys())\n",
        "    val_dict=list(dict_now.values())\n",
        "      \n",
        "    return new_datasets_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGwnKbCPae-L"
      },
      "outputs": [],
      "source": [
        "new_datasets_sum=merge_all(dict_now, biotech, ipo_new_datasets, list_real)\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_datasets_sum"
      ],
      "metadata": {
        "id": "_aJ-Mnc-RB4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_datasets_sum.columns[71:new_datasets_sum.shape[1]]"
      ],
      "metadata": {
        "id": "CKwEu5ZY5nZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX8QoPkpWcAL"
      },
      "outputs": [],
      "source": [
        "new_datasets_sum.to_csv(final_str)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}